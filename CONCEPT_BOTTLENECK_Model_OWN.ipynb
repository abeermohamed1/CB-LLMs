{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abeermohamed1/CB-LLMs/blob/main/CONCEPT_BOTTLENECK_Model_OWN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNo3Czo8tO2j",
        "outputId": "3f81b62d-7856-4ecb-e1e6-b11ac8790c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CB-LLMs'...\n",
            "remote: Enumerating objects: 140, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 140 (delta 50), reused 35 (delta 35), pack-reused 72 (from 1)\u001b[K\n",
            "Receiving objects: 100% (140/140), 936.63 KiB | 14.87 MiB/s, done.\n",
            "Resolving deltas: 100% (61/61), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/abeermohamed1/CB-LLMs.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aec7265",
        "outputId": "23468fbb-e7b8-4e9b-ed0d-7c5bdf21078d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CB-LLMs/classification\n"
          ]
        }
      ],
      "source": [
        "%cd CB-LLMs/classification/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b26e1501",
        "outputId": "210c3567-59e6-4ed7-a94b-b4ef5f914f46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.2.0 (from -r requirements.txt (line 1))\n",
            "  Downloading torch-2.2.0-cp312-cp312-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting transformers==4.44.0 (from -r requirements.txt (line 2))\n",
            "  Downloading transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets==3.0.2 (from -r requirements.txt (line 3))\n",
            "  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting peft==0.13.2 (from -r requirements.txt (line 4))\n",
            "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting glm_saga==0.1.2 (from -r requirements.txt (line 5))\n",
            "  Downloading glm_saga-0.1.2.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate==0.4.0 (from -r requirements.txt (line 6))\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting torchvision==0.17.0 (from -r requirements.txt (line 7))\n",
            "  Downloading torchvision-0.17.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting scikit-learn==1.3.0 (from -r requirements.txt (line 8))\n",
            "  Downloading scikit-learn-1.3.0.tar.gz (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a94adb6",
        "outputId": "3bf41dca-2bb0-42a8-d841-e7761c3aa1e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'temp_repo'...\n",
            "remote: Enumerating objects: 138, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 138 (delta 0), reused 0 (delta 0), pack-reused 135 (from 1)\u001b[K\n",
            "Receiving objects: 100% (138/138), 20.01 KiB | 6.67 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/cesun/cbllm-classification temp_repo\n",
        "!mv temp_repo/mpnet_acs .\n",
        "!rm -rf temp_repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b93f36e5"
      },
      "outputs": [],
      "source": [
        "%%writefile requirements.txt\n",
        "torch==2.2.0\n",
        "transformers==4.44.0\n",
        "datasets==3.0.2\n",
        "peft==0.13.2\n",
        "glm_saga==0.1.2\n",
        "evaluate==0.4.0\n",
        "torchvision==0.17.0\n",
        "scikit-learn==1.3.0\n",
        "numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1e07db41"
      },
      "outputs": [],
      "source": [
        "!python finetune_black_box.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b636a1b1",
        "outputId": "b232e28d-a63d-4986-fb90-7072b3fcc21d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading data...\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "test data len:  1821\n",
            "tokenizing...\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Map: 100% 1821/1821 [00:00<00:00, 3716.61 examples/s]\n",
            "creating loader...\n",
            "preparing backbone(roberta)+CBL...\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "get concept features...\n",
            "torch.Size([1821, 2, 208])\n",
            "avg error rate: 0.012142440163455925\n"
          ]
        }
      ],
      "source": [
        "!python print_concept_contributions.py --cbl_path mpnet_acs/SetFit_sst2/roberta_cbm/cbl_acc.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a182125",
        "outputId": "13fdea7b-67d6-4dfa-888d-171a0aed946f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-11-25 20:44:33.965675: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764103474.365072   20404 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764103474.472857   20404 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764103475.440706   20404 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764103475.440815   20404 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764103475.440820   20404 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764103475.440825   20404 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-25 20:44:35.571335: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "loading data...\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "test data len:  1821\n",
            "tokenizing...\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Map: 100% 1821/1821 [00:00<00:00, 4963.71 examples/s]\n",
            "creating loader...\n",
            "preparing backbone(roberta)+CBL...\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "get concept features...\n",
            "Downloading builder script: 4.20kB [00:00, 6.64MB/s]\n",
            "{'accuracy': 0.9406919275123559}\n"
          ]
        }
      ],
      "source": [
        "!python test_CBLLM.py --cbl_path mpnet_acs/SetFit_sst2/roberta_cbm/cbl_acc.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58ff54bb",
        "outputId": "e5240a92-a87a-40d3-f849-8cbbedb3abe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading data...\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "test data len:  1821\n",
            "tokenizing...\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Map: 100% 1821/1821 [00:00<00:00, 5746.14 examples/s]\n",
            "creating loader...\n",
            "preparing backbone(roberta)+CBL...\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "get concept features...\n",
            "avg error rate: 0.03076923076923077\n"
          ]
        }
      ],
      "source": [
        "!python print_concept_activations.py --cbl_path mpnet_acs/SetFit_sst2/roberta_cbm/cbl_acc.pt"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIE1QGr8ZVKBztEW2ZeiBB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}